[
["preface.html", "Notes for Math 253: Statistical Computing and Machine Learning Preface Math 253 and the Macalester statistics curriculum These notes are written in Bookdown", " Notes for Math 253: Statistical Computing and Machine Learning Daniel Kaplan Fall 2016, Macalester College Preface Math 253 and the Macalester statistics curriculum Math 253, Statistical Computing and Machine Learning, is a course at Macalester College. The course comes early in our curriculum for the statistics major. Currently, that curriculum looks like: Comp 110, Data Computing, a no-prerequisite course in data wrangling and visualization. The main tools in the course are R, dplyr, and ggplot. Math 125, Epidemiology. This course also has no pre-requisites. It’s designed to teach quantitative and statistical literacy in the context of public health and decision making. Unlike the other courses in our curriculum, Math 125 is not computer intensive. This is an elective for the statistics major. Math 155, Introduction to Statistical Modeling. This is our main entry-level statistics course. It also has no pre-requisites, but we encourage students to take a course in our calculus sequence: Applied Multivariate Calculus I, II, and III. The course covers important concepts in modeling: model architectures and fitting using mainly linear and logistic regression, covariation and adjustment, interpretation of model coefficients, inference techniques such as analysis of variance and co-variance and the ways these techniques can inform the decisions needed to build useful models, causality including techniques for making reasonable conclusions about causation from observational data. The course makes very extensive and intensive use of R and the mosaic package for R. This course, Math 253, Statistical Computing and Machine Learning. Math 253 introduces a broader set of model architectures (e.g. those associated with “machine learning” such as support vector machines) and the trade-offs that make machine learning a human skill rather than a push button mechanism. The main text is Introduction to Statistical Learning in R. Computing in R is used intensively in the course. Math 155 is a pre-requisite. The computing used in that course is the only pre-requisite. A small part of Math 253 is given to basic programming in R, but the large majority is about the mathematical and statistical concepts involved in learning from data and the exercise of a variety of architectures for classification and regression models. Math 253 is placed intentionally in the middle of our statistics curriculum to make it accessible to many students who are interested and may have use for the techniques, but whom are not primarily interested in statistics per se. Upper level courses including: Math 454: Bayesian statistics Math 453: Biostatistics Math 454: Mathematical statistics Supporting courses including: Math 354: Probability Math 135: Applied Multivariate Calculus I Math 236: Linear algebra Comp 123: Core conceptsin computer science Electives such as Math 432: Mathematical modeling Math/Comp 365: Numerical linear algebra Comp 302: Introduction to database management systems These notes are written in Bookdown The document uses an elaboration on R/Markdown, called “Bookdown.” I don’t yet know if this will be a good way to maintain and distribute class notes. Some advantages: All the notes are in one place. Students and other instructors can clone the notes for their own uses. People spotting mistakes can contribute corrections via the “pull request” mechanism supported by Bookdown working with GitHub. Multiple instructors can contribute to the notes via GitHub. This is the stated purpose behind Bookdown — allowing book-length publications to be authored by many authors. Disadvantages: The notes are always a work in progress. Don’t be mislead by the polish that RMarkdown and Bookdown give to the notes. "],
["introduction.html", "Topic 1 Introduction 1.1 Statistical and Machine Learning 1.2 Review of Day 1 1.3 Theoretical concepts ISL §2.1 1.4 Many techniques 1.5 Basic dicotomies in machine learning 1.6 Day 2 theory: accuracy, precision, and bias 1.7 Programming Basics I: Names, classes, and objects 1.8 Day 2 in-class programming activity 1.9 Review of Day 2 1.10 A Classifier example", " Topic 1 Introduction Subjects Overview of statistical learning. Getting started with R, RStudio, and RMarkdown Reading: Chapter 2 of ISL Programming basics 1: Names, classes, and objects 1.1 Statistical and Machine Learning The two terms, “statistical learning” and “machine learning,” reflect mainly the artificialities of academic disciplines. Statisticians focus on the statistical aspects of the problems Computer scientists are interested in “machines”, including hardware and software. “Data Science” is a new term that reflects the reality that both statistical and machine learning are about data. Techniques and concepts from both statistics and computer science are essential. 1.1.1 Example 1: Machine translation of natural languages Computer scientists took this on. Identification of grammatical structures and tagging text. Dictionaries of single-word equivalents, common phrases. Story from early days of machine translation: Start with English: “The spirit is willing, but the flesh is weak.” Translate into Russian Translate back into English. Result: “The vodka is good, but the meat is rotten.” Statistical approach: Take a large sample of short phrases in language A and their human translation into language B: the dictionary Find simple measures of similarity between phrases in language A (e.g. de-stemmed words in common) Take new phrase in language A, look up it’s closest match in the dictionary phrases in language A. Translation is the corresponding dictionary entry in language B Where did the sample of phrases come from? European Union documents routinely translated into all the member languages. Humans mark correspondence. “Mechanical Turk” dispersal of small work tasks. Result: Google translate. 1.1.2 Example 2: From library catalogs to latent semantic indexing Early days: computer systems with key words and search systems (as in library catalogs) Now: dimension reduction (e.g. singular value decomposition), angle between specific documents and what might be called “eigen-documents” Result: Google search 1.1.3 Computing technique Each student in the class as a personal repository on GitHub. The instructor is also a contributor to this repository and can see anything in it. Complete instructions for doing this are in the appendix. Set up some communications and security systems (e.g. an RSA key) Clone your repository from GitHub. It is at an address like github.com/dtkaplan/math253-bobama. Day 1 Programming Activity 1.2 Review of Day 1 We discussed what “machine learning” means and saw some examples of situations where machine-learning techniques have been used successfully to solve problems that had at best clumbsy solutions before. (Natural language translation, catalogs of large collections of documents.) We worked through the process of connecting RStudio to GitHub, so that you can use your personal repository for organizing, backing up, and handing in your work. The Day-1 programming activity introduced some basic components of R: assignments, strings, vectors, etc. 1.3 Theoretical concepts ISL §2.1 “Data science” lies at the intersection of statistics and computer science. 1.3.1 Statistics concepts Sampling variability Bias and variance Characterization of precision Function estimation frameworks, e.g. generalized linear models Assumed probability models Prior and posterior probabilities (Bayesian framework) 1.3.2 Computing concepts Algorithms Iteration Simulation Function estimation frameworks, e.g. classification trees, support vector machines, artificial intelligence techniques Kalman filters 1.3.3 Cross fertilization Assumed probability models supplanted by simulation Randomization and iteration Cross validation Bootstrapping Model interpretibility Rather than an emphasis on the output of a function, interest in what the function has to say about how the world works. 1.4 Many techniques “Learning” is an attractive word and suggests that “machine learning” is an equivalent for what humans do. Perhaps it is to some extent … But “modeling” is a more precise term. We will be building models of various aspects of the world based on data. Model: A representation for a purpose. Blueprints, dolls, model airplanes. Mathematical model: A model built of mathematical stuff polynomials: Math 155 functions more generally: e.g. splines, smoothers, … trees geometry of distance: e.g. which exemplar are the inputs closest to? projection onto subspaces Statistical model: A mathematical model founded on data. 1.4.1 Unsupervised learning Wait until the end of the semester. We will be doing only supervised learning until late in the course. 1.4.2 Supervised learning: We have a set of cases, \\(i = 1, 2, 3, \\ldots, n\\), called the training data. For each case, we have an input \\({\\mathbf X_i}\\) consisting potentially of several variables measured on that case. The subscript \\(i\\) in \\({\\mathbf X_i}\\) means that we have one \\({\\mathbf X}\\) for each case. The boldface \\({\\bf X}\\) means that the input can be multi-dimensional, that is, consisting of multiple variables. For each case, we have an output \\(Y_i\\). We want to learn the overall pattern of the relationship between the inputs \\({\\mathbf X}\\) and the outputs \\(Y\\), not just for our \\(n\\) training cases, but for potential cases that we have not encountered yet. These as yet unencountered cases are thought of as the testing data. We are going to represent the pattern with a function \\(\\hat{f} : {\\bf X} \\rightarrow Y\\). Sometimes I’ll use the word model instead of function. A model is a representation for a purpose. A function is a kind of representation. So some models involve functions. That’s the kind we’ll focus on in this course. I say “model” out of habit, but it’s a good habit that reminds us that the purpose of the function is important and we should know what that purpose is when we undertake learning. 1.5 Basic dicotomies in machine learning There are fundamental trade-offs that describe the structure of learning from data. There are also trade-offs that arise between different methods of learning. Finally, there are dicotomies that stem from the different purposes for learning. These dicotomies provide a kind of road map to tell you where are are and identify where you might want to go. And, as always, it’s important to know why you are doing what you’re doing: your purpose. 1.5.1 Purposes for learning: Make predictions. Given new inputs, e.g. data about an event, predict what the result of the event will be. e.g. weather forecasting, credit card fraud, success in college, …. In statistics, this is sometimes thought of as “analyzing data from an observational study.” Anticipate the effects of an intervention that we impose, e.g., giving a patient a drug, changing funding for schools, … Traditionally in statistics, this has been tied exclusively to data from experiments. There is now greater acceptance that experiments are not always possible, and it’s important to be able to make reasonable inferences about causation from observational studies. Find structure in a mass of data. 1.5.2 Dicotomies make predictions vs capture causal mechanism (in this course: common sense. There are also formal techniques to guide causal reasoning.) flexibility vs variance (need some tools for this) black box vs interpretable models (comparing model architectures) reducible vs irreducible error (“bias” vs “residuals”) regression vs classification (easy!) supervised vs unsupervised learning (easy!) 1.5.3 Prediction versus mechanism Example: Malignancy of cancer from appearance of cells. Works for guiding treatment. Does it matter why malignant cells have the appearance they do? Story: Mid-1980s. Heart rate variability spectral analysis and holter monitors. (Holters were cassette tape recorders set to record ECG very, very slowly. Spectral analysis breaks down the overal signal into periodic components.) Very large spike at 0.03 Hz seen in people who will soon die. Could use for prediction, but researchers were also interested in the underlying physiological mechanism. Causal influences. We want to use observations to inform our understanding of what influences what. Story continued: The very large spike was the “wow and flutter” in the cassette tape mechanism. This had an exact periodicity: a spike in the spectrum. If the person was sick, their heart rate was steady: they had no capacity to vary it as other conditions in the body (arterial compliance, venus tone) called for. Understanding what happens in cardiac illness is, in part, about understanding how the various control systems interact. 1.5.4 Flexibility versus variance In traditional statistics, this is often tied up with the concept of “degrees of freedom.” Not flexible: Figure 1.1: Individual fits miss how the explanatory variables interact. ISL Figure 2.1 Flexible: Figure 1.2: Such detailed patterns are more closely associated with physical science data than with social/economic data. ISL Figure 2.2 And in multiple variables: Not flexible: Figure 1.3: ISL Figure 2.4 Flexible: Figure 1.4: ISL Figure 2.6 1.5.5 Black box vs interpretable models Many learning techniques produce models that are not easily interpreted in terms of the working of the system. Examples: neural networks, random forests, etc. The role of input variables is implicit. Characterizing it requires experimenting on the model. In other learning techniques, the role of the various inputs and their interactions is explicit (e.g. model coefficients). The reason to use a black-box model is that it can be flexible. So this tradeoff might be called “flexibility vs interpretability.” A quick characterization of several model architectures (which they call “statistical learning methods”) Figure 1.5: ISL Figure 2.7 1.5.6 Reducible versus irreducible error How good can we make a model? How do we describe how good it is? What does this mean? (from p. 19) \\[\\begin{array}{rcl} E(Y - \\hat{Y})^2 &amp; = &amp; E[f(X) + \\epsilon - \\hat{f}(X)]^2\\\\ &amp; = &amp; \\underbrace{[f(X) - \\hat{f}(X)]^2}_{Reducible} + \\underbrace{Var(\\epsilon)}_{Irreducible}\\\\ \\end{array}\\] Notation: \\(X\\) — the inputs that determine the output \\(Y\\). \\(Y\\) — the output, that is, the quantity we want to predict \\(\\hat{Y}\\) — our prediction hat means estimated, no hat means “real” (whatever that might mean) \\(E(Y - \\hat{Y})^2\\) — the mean of the square difference between our prediction and the “real” value. \\(E\\) means “expectation value.” \\(f(X)\\) — what \\(Y\\) would be, ideally, for a given \\(X\\) \\(\\hat{f}(X)\\) — our estimate of \\(f(X)\\) \\(\\epsilon\\) — but \\(Y\\) is subject to other, “random” influences. \\(\\epsilon\\) represents these. \\(\\epsilon\\) is a misleading notation because it may not be at all small in practice. But \\(\\epsilon\\) is alway centered on zero (by definition). \\(|f(X) - \\hat{f}(X)|\\) — the magnitude of the difference between the “real” \\(f()\\) and our estimate. This can be made small by collecting more data using a more flexible model expanding the set of inputs considered \\(Var(\\epsilon)\\) — the “variance” of \\(\\epsilon\\). This is the mean square of \\(\\epsilon\\), that is, \\(E(\\epsilon^2)\\). 1.5.7 Regression versus classification Regression: quantitative response (value, probability, count, …) Classification: categorical response with more than two categories. (When there are just two categories, regression (e.g. logistic regression) does the job.) 1.5.8 Supervised versus unsupervised Demographics groups in marketing. Poverty vs middle-class Political beliefs … left vs right? Figure 1.6: ISL Figure 2.8 1.6 Day 2 theory: accuracy, precision, and bias 1.6.1 Figure 2.10 In constructing a theory, it’s good to have a system you can play with where you know exactly what is going on: e.g. a simulation. The dark blue line in the left panel is a function the authors created for use in a simulation: Figure 1.7: ISL Figure 2.9 The dots are data the textbook authors generated from evaluating the function at a few dozen values of \\(x\\) and adding noise to each result. The difference between the dots’ vertical position and the function value is the residual, which they are calling the error. The mean square error MSE is \\[\\mbox{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - f(x_i))^2\\] Take this notation apart. What’s \\(n\\)? What’s \\(i\\)? Suppose that \\(f(x)\\) were constant. In that situation, what kind of statistical quantity does this resemble? In actual practice, we don’t know \\(f(x)\\). (Indeed, it’s a matter of philosophy whether this is an \\(f(x)\\) — it’s a kind of Platonic form.) Here we know \\(f(x)\\) because we are playing a game: running a simulation. Looking again at the left panel in Figure 2.9, you can see three different functions that they have fitted to the data. It’s not important right now, but you might as well know what these model architectures are: Linear regression line (orange) Smoothing splines (green and light blue). A smoothing spline is a functional form with a parameter: the smoothness. The green function is less smooth than the light blue function. That smoothness measure can also be applied to the linear regression form Each of these three functions were fitted to the data. Another word for fitted is trained. As such, we use the term training error for the difference between the data points and the fitted functions. Also, because the functions are not the Platonic \\(f(x)\\), they are written \\(\\hat{f}(x)\\). For each of the functions, the training MSE is \\[\\mbox{Training MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{f}(x_i))^2\\] Right panel of the graph is something completely different: both the axes are different than in the left panel. x-axis: the smoothness of the functions. This is labelled flexibility. The three x positions correspond to the smoothness of the three models. This is measured as the effective number of parameters of the function. Why does the straight-line function have a smoothness of 2? y-axis: the MSE The dots connected by the gray curve show the training MSE of the three models. The dots connected by the orange curve show the testing MSE of the three models. The continuous curves were constructed by calculating the MSE for many more values of smoothness than shown in the left panel. How did they measure the training MSE? 1.6.2 Another example: A smoother simulated \\(f(x)\\). Figure 1.8: ISL Figure 2.10 What’s different between the right panel of 2.9 and that of 2.10? 1.6.3 What’s the “best” of these models? When examining training MSE, the more flexible model has the smaller MSE. This answer is pre-ordained, regardless of the actual shape of the Platonic \\(f(x)\\). In traditional regression, we use ANOVA or *adjusted$ \\(R^2\\) to help avoid this inevitability that more complicated models will be closer to the training data. Another approach to this is to use testing MSE rather than training MSE. So pick the model with flexibility at the bottom of the U-shaped testing MSE curve. 1.6.4 Why is testing MSE U-shaped? Bias: how far \\(\\hat{f}(x)\\) is from \\(f(x)\\) Variance: how much \\(\\hat{f}\\) would vary among different randomly selected possible training samples. In traditional regression, we get at the variance by using confidence intervals on parameters. The broader the confidence interval, the higher the variation from random sample to random sample. These confidence intervals come from normal theory or from bootstrapping. Bootstrapping is a simulation of the variation in model fit due to training data. Bias decreases with higher flexibility. Variance tends to increase with higher flexibility. Irreducible error is constant. Figure 1.9: ISL Figure 2.12 1.6.5 Measuring the variance of independent sources of variation Simulation: Make and edit a file Day-02.Rmd. 1.6.5.1 Explore Add three different sources of variation. The width of the individual sources is measured by the standard deviation sd=. n &lt;- 1000 sd( rnorm(1000, sd=3) + rnorm(1000, sd=1) + rnorm(1000, sd=2) ) ## [1] 3.569118 Divide into small groups and construct a theory about how the variation in the individual components relates to the variation in the whole. test whether your theory works for other random distributions, e.g. rexp() 1.6.5.2 Result (Don’t read until you’ve drawn your own conclusions!) The variance of the sum of independent random variables is the sum of the variances of the individual random variables. 1.6.6 Equation 2.7 \\[E( y - \\hat{f}(x) )^2 = \\mbox{Var}(\\hat{f}(x)) + [\\mbox{Bias}(\\hat{f}(x))]^2 + \\mbox{Var}(\\epsilon)\\] Breaks down the total “error” into three independent sources of variation: How \\(y_i\\) differs from \\(f(x_i)\\). This is the irreducible noise: \\(\\epsilon\\) How \\(\\hat{f}(x_i)\\) (if fitted to the testing data) differs from \\(f(x_i)\\). This is the bias. How the particular \\(\\hat{f}(x_i)\\) fitted to the training data differs from the \\(\\hat{f}(x_i)\\) that would be the best fit to the testing data. \\[\\underbrace{E( y - \\hat{f}(x) )^2}_{\\mbox{Total error}} = \\underbrace{\\mbox{Var}(\\hat{f}(x))}_{\\mbox{source 3.}} + \\underbrace{[\\mbox{Bias}(\\hat{f}(x))]^2}_{\\mbox{source 2.}} + \\underbrace{\\mbox{Var}(\\epsilon)}_{\\mbox{source 1.}}\\] 1.7 Programming Basics I: Names, classes, and objects 1.7.1 Names Composed of letters, numbers, _ and .. - Don’t use . — it’s a bad habit. But plenty of people do. - Can’t lead with a number. - Capitalization counts. - Unquoted (… almost always) 1.7.2 Objects Information (bits) in a particular format. - Different formats for different purposes. - The format is the class() or mode(). mode is more basic than class. Assignment: Give a name to an object 1.7.3 Classes Different classes represent different kinds of things. They typically have different operations that are relevant. 1-dimensional homogeneous collections of numbers or of character strings. These collections are called vectors 1-dimensional means you need only one index to refer to a specific element length(), which can be zero. Operations, e.g. sum(), mean(), max() … 2-dimensional homogeneous collections of numbers or of character strings. These collections are called matrices 2-dimensional means you need two indices to refer to a specific element. dim() Operations, e.g., t(), colSums(), rowSums(), %*%, … 1-dimensional heterogeneous collections: lists Data frames Functions 1.8 Day 2 in-class programming activity Day 2 activity 1.9 Review of Day 2 \\(f({\\mathbf X})\\) versus \\(\\hat{f}({\\mbox{X}})\\): Platonic idea versus what we get out of the training data. Quip: “The hat means there’s a person underneath the model.” Mean Square Error — like the standard deviation of residuals Training vs testing data Smoothness, a.k.a. flexibility, model degrees of freedom More flexibility \\(\\rightarrow\\) better training MSE Components of MSE Irreducible random noise: \\(\\epsilon\\) Bias: \\(f({\\mathbf X}) - \\hat{f}({\\mathbf X})\\) Caused by too much smoothness Caused by omitting a relevant variable Caused by including an irrelevant variable \\(Var(\\hat{f}({\\mathbf X}))\\) — how much \\(\\hat{f}\\) varies from one possible training set to another. Increased by too many degrees of freedom: overfitting Increased by collinearity and multi-collinearity. Increased by large \\(\\epsilon\\) Decreased by large \\(n\\) Regression vs classification Different kinds of functions. A classifier has output as a categorical level. A regression has output as a number. Prediction vs inference Two different kinds of purpose. There may well be different kinds of functions best suited to each purpose. Accuracy vs interpretability We always want models to be accurate. Whether we need to be able to interpret the model depends on our overall purpose. Reducible error vs irreducible error It’s good to know how accurate our models can get. That gives a goal for trying out different types of models to know when we don’t need to keep searching. 1.10 A Classifier example A classification setting: Blood cell counts. Build a machine which takes a small blood sample and examines and classifies individual white blood cells. Figure 1.10: Blood cell classification The classification is to be based on two measured inputs, shown on the x- and y-axes. Training data has been developed where the cell was classified “by hand.” In medicine, this is sometimes called the gold standard. The gold standard is sometimes not very accurate. Here, each cell is one dot. The color is the type of the cell: granulocytes, lymphocytes, monocytes, … "],
["linear-regression.html", "Topic 2 Linear Regression 2.1 Day 4 Overview 2.2 Small data 2.3 Selecting model terms 2.4 Programming basics: Graphics 2.5 In-class programming activity 2.6 Review of Day 4 2.7 Regression and Interpretability 2.8 Measuring Accuracy of the Model 2.9 Bias of the model 2.10 Forward, backward and mixed selection 2.11 In-class programming activity", " Topic 2 Linear Regression 2.1 Day 4 Overview The linear model (e.g. what lm() does) A variety of questions relevant to different purposes, e.g. how good will a prediction be? what’s the strength of an effect? is there synergy between different factors? 2.1.1 ISL book’s statement on why to study linear regression “Though it may seem somewhat dull compared to some of the more modern statistical learning approaches described … later …, linear regression is still a useful and widely used statistical learning method. Moreover, it serves as a good jumping-off point for newer approaches…. Consequently, the importance of having a good understanding of linear regression before studying more complex learning methods cannot be overstated.” Concepts from linear regression: Choice of explanatory variables and model term (such as interaction). “Degrees of freedom” Ease of interpretability of coefficients and their standard errors. 2.2 Small data The regression techniques were developed in an era of small data, such as that that might be written in a lab notebook or field journal. As a result: Emphasis on very simple descriptions, such as means, differences between means, simple regression. Theoretical concern with details of distributions, such as the t-distribution. No division into training and testing data. Data are too valuable to test! (Ironic, given the importance of replicability in the theory of the scientific method.) As a consequence of (3), there’s a great deal of concern about assumptions, e.g. linearity of \\(f({\\mathbf X})\\) structure of \\(\\epsilon\\): IID — Independent and Identically Distributed uncorrelated between cases each is a draw from the same distribution. 2.3 Selecting model terms The regression techniques Heirarchical principal Increase in \\(R^2\\) 2.3.1 Theory of whole-model ANOVA. Standard measure: \\(\\frac{\\mbox{Explained amount}}{\\mbox{Unexplained amount}}\\) Examples: Standard error of mean: \\(\\frac{\\hat{\\mu}}{\\sigma / n}\\) – note the \\(n\\). t statistic on difference between two means: \\(\\frac{\\hat{\\mu}_1 - \\hat{\\mu}_2}{\\sigma / (n-1)}\\) F statistic: \\(\\frac{SS / df1}{SSR / df2}\\) df1 is the number of degrees of freedom involved by the model or model term under consideration. df2 is \\(n - (p - 1)\\) where \\(p\\) is the total degrees of freedom in the model. (I called this \\(m\\) in the Math 155 book.) The intercept is what the \\(-1\\) is about: the intercept can never account for case-to-case variation. Trade-off between eating variance and consuming degrees of freedom. The \\(R^2\\) versus \\(p\\) picture. Adjusted \\(R^2\\) Whole model ANOVA. ANOVA on model parts 2.4 Programming basics: Graphics Basic functions: Create a frame: plot(). Blank frame: plot( , type=&quot;n&quot;) set axis limits, Dots: points(x, y), pch=20 Lines: lines(x, y) — with NA for line breaks Polygons: polygon(x, y) — like lines but connects first to last. fill Color, size, … rgb(r, g, b, alpha), “tomato” 2.5 In-class programming activity Day 4 activity Drawing a histogram. 2.6 Review of Day 4 2.6.1 Graphics basics API for graphics: plot(), points(), lines(), polygon(), text(), … Create a plotting frame: plot() Write a function that makes this more convenient to use. What features would you like. blank_frame &lt;- function(xlim, ylim) { } Write a function to draw a circle. What do you want the interface to look like? What arguments are essential? What options are nice to have? 2.7 Regression and Interpretability Regression models are generally constructed for the sake of interpretability: Global linearity Coefficients are indication of effect size. The coefficients have physical units. Term by term indication of statistical significance 2.8 Measuring Accuracy of the Model \\(R^2\\) - Var(fitted)/Var(response) Adjusted \\(R^2\\) - takes into account estimate of average increase in \\(R^2\\) per junk degree of freedom Residual Standard Error - Sqrt of Average square error per residual degree of freedom. The sqrt of the mean square for residuals in ANOVA 2.9 Bias of the model Perhaps effect of TV goes as sqrt(money) as media get saturated? Perhaps there is a synergy that wasn’t included in the model? Whole model ANOVA. ANOVA on model parts Adjusted \\(R^2\\) Run an example on College data from ISLR package data(College, package=&quot;ISLR&quot;) College$Yield &lt;- with(College, Enroll/Accept) mod1 &lt;- lm(Yield ~ Outstate + Grad.Rate + Top25perc, data=College) What variables matter? How good are the predictions? How strong are the effects? 2.10 Forward, backward and mixed selection Use the College model to demonstrate each of the approaches by hand. Start with pairs() or write an lapply() for the correlation with Yield? Create a whole bunch of model terms “main” effects “interaction” effects nonlinear transformations: powers, logs, sqrt, steps, … categorical variables Result: a set of \\(k\\) vectors that we’re interested to use in our model. Considerations: not all of the \\(k\\) vectors may pull their weight two or more vectors may overlap in how they eat up variance Algorithmic approaches: Try all combinations, pick the best one. computationally expensive/impossible \\(2^k\\) possibilities what’s the sensitivity of the process to the choice of training data? “Greedy” approaches 2.11 In-class programming activity Day 5 activity Drawing a histogram. "],
["appendices.html", "Appendices", " Appendices "],
["connecting-rstudio-to-your-github-repository.html", "Connecting RStudio to your GitHub repository 2.12 Setting up your Math 253 repository 2.13 Using your repository 2.14 Why are we doing this?", " Connecting RStudio to your GitHub repository 2.12 Setting up your Math 253 repository First, we have to set up communications between your RStudio system and GitHub. You need only do this once on each RStudio system. But if you want to work on, say, a new computer or new RStudio server, you’ll need to do it again. Make sure you have a GitHub account. You’ll need two pieces of information about your account: Your GitHub ID. For the instructions, I’ll call in brosenberg, but remember to use your own ID The email address you gave when you set up your account. I’ll use brosenberg@macalester.edu for the example. Start up RStudio and do the following: In the console, give these commands: system(&#39;git config --global user.name &quot;Brian MacAlistair&quot;&#39;) system(&#39;git config --global user.email &quot;brosenberg@macalester.edu&quot;&#39;) system(&#39;git config --global --list&#39;) Select the menu item Tools/Global Options/Git-SVN. You will see a button to “Create RSA key …”. If the box above that button is empty, press the button. Otherwise continue on …. Click “View public key” and copy the resulting displayed text to your clipboard. Go to your GitHub account. It will have an address like github.com/brosenberg. Press the “Edit Profile” button, then select “SHS and GPG keys.” Press the “New SSH key” button. Two text boxes will appear. In the smaller one, insert some description of your RStudio system, e.g. rstudio.macalester.edu or my own laptop. In the larger one, paste the text you copied to your keyboard in step 2c. Almost done … A GitHub repository has been set up for you. It will has a URL in this form: &lt;github.com/dtkaplan/math253-brosenberg&gt;. If that doesn’t work, ask for help. There might have been some mistake or delay in setting up your repository, and only dtkaplan can fix things. Direct your browser to the address of your repository. On the right side of the page, there is a green button: “Clone or download”. Press it. A small dialog panel will appear. It should say, “Clone with SSH”. (If not, press the small “Use SSH” link to the right.) Click on the small clipboard icon. This will copy an address to your clipboard. The address starts with git@github.com. Go back to your RStudio system. Select File/New Project/Version Control/GIT. A dialog box will appear. Paste the address from 4c into the topmost text-entry widget in the dialog box. Press “Create project.” Some stuff will happen. Ultimately, you should see RStudio restart and the name of your repository (e.g. math253-brosenberg) will be on the upper right corner of the RStudio window. (If you are using the server version of RStudio, you might have to refresh your browser to see the change.) 2.13 Using your repository You will be modifying files that are already in your repository, for instance 01-Programming.Rmd. Make sure that the project displayed in your RStudio is the right one, e.g. math253-brosenberg Open, edit, debug, and revise the files you are working on in the normal way. You should knit the file to HTML frequently. This helps you spot problems early. You’ll mainly be working with .Rmd files. When you’re satisfied with things, knit the file to produce HTML one final time. Ready to “hand in” your work? Go to the “Git” tab in RStudio. You should see at least two files listed: the file you edited and the corresponding HTML file. “Stage” the files by checking the little boxes. “Commit” the files by pressing the “commit” button. You will be asked to write a message. Choose something short and informative, e.g. “Day 1 project submission.” A dialog box will appear with some text indicating what was in the commit. Press the “Pull” arrow. Press the “Push” arrow. Assuming that no errors appear, you are all done! Well … actually you’re never “all done.” You will often want to revise your work. Follow the same steps as above. It is not cheating to revise your work, even after you hand it in. I encourage you to do this, be it the next day or several weeks after you handed it in. Git keeps a detailed history of all your commits, so I can always find any version of the file that I need. 2.14 Why are we doing this? We speak of “handing in” assignments, projects, and other work for a course. But just as we no longer “dial” a telephone, there is no longer a hand involved in handing in. With course support systems like Moodle, you “hand in” by uploading to a server a copy of the file containing your work. You have a working copy of your work and, when you’re finished with your work, you upload a final copy. Making a copy has implications that can get in the way of carrying out your work. The problem is that there is usually nothing in the copy that indicates unambiguously where it comes from. If you want to revise the document, should you be revising the working document or the final copy? The word “final” suggests the traditional approach to this question. Once the work is done and the document is finalized, you no longer make any changes. It turns out that “final” does not accord well with the way that people work in collaboration. For all the time that people work with a document, there is a continuing process of revision and refinement. You may think something is final, but in a collaboration that’s not entirely your call; you may find out that it isn’t yet finished. Insofar as your document contains web links to other documents, the situation becomes even more complex, since those other documents may change. An extreme instance of this lack of finality appears in software development. Software is complex and bugs are apt to be discovered even after the “final” release. Any piece software written by you or your team relies on and communicates with other software. Changes in that other software can imply a need to revise your own software. We’ve become familiar with the idea of versions of software: R 3.3.2, Word 2016, etc. There are advantages in thinking about documents in the same way we think about software.1 Or, put another way, there are advantages to thinking about working with documents using the same tools that computer programmers use to manage their own complex collaborations with other programmers and with other software. That’s what we’re going to do. There are two reasons: (1) it provides a superior way of managing communications and (2) it is the way things are heading in general, so the skills and concepts you develop will help you in your future work and career. To outline the components of the process … You are going to be writting documents using the .Rmd (R/Markdown) format. You’ll use this even if there happens not to be any R content in the document. Each document that you create as part of your work for this course will be located in an RStudio “project.” A project is a means of grouping together related files. The project and the files within it will be located on your own computer. This might be your own laptop or a server. Your project will be cloned to storage on other computers. In particular, there will be a clone on the instructor’s computer and another clone on a server in the cloud. The cloud server is maintained by GitHub.com. This is not the only such server, but it is the one we are going to use. Both GitHub.com and your computer (and any other computers the project is cloned on) communicate with a system called “git.” The git system provides facilities for keeping a thorough record of the changes you make in files contained in your project. You control how fine-grained you want this record to be. The means for doing this is to take a snapshot of the current state of your project. Such a snapshot is called a “commit.” You have control of which of the documents will have changes recorded in the history; directing git to include the changes to a particular file (or even its creation) is called “staging” the file. At times of your own choice, you can synchronize/update the clone of the web server to the most recent commit of your project. This is called “pushing” the commit. Also at times of your choosing, you can synchronize/update your own clone of the project to the one on the GitHub server. This is called “pulling” a commit. Pulling and pushing are the means by which you collaborate with others on the project. Just as you will push your changes to the server, others will be pushing their own changes. You pull to synchronize your clone of the project with the changes that have been pushed by others. In a typical work session, you will commit the current state of your project, then pull from the server, make the revisions you want in your clone. commit as often as you like within a session. Committing provides you with a marker. If something went wrong and you want to undo your revisions, it’s very easy to do so to the point where you last made a commit. Some people commit every paragraph. You decide. It takes very little time and costs nothing. If your file is intended to be translated to HTML, make sure to do this and to stage and commit the resulting version of the HTML file. When you are done with that session’s revisions, you — wait for it! — once again pull from the server. This lets you capture any changes that others made while you were revising your own clone of the project. It’s important because, sometimes, your changes will conflict with those made by others and pulling gives git a chance to bring any such conflicts to your attention. (Git will not let you push until all such conflicts have been resolved.) Finally, you push to the server, so that the clone on the server is synchronized to the changes you have made. At the instant after your push, you are now ready to continue at step (c). If you recommence work after enough time has elapsed that someone else might have pushed their own clone to the server, you should instead continue at step (a). You don’t need to be anxious about this; git will identify any conflicts that might have arisen due to another collaborator’s commits after step (f). It’s up to you to decide how often you should push. Pushing serves two purposes: It “backs up” your work to the cloud, so you won’t lose anything done up to the point of the push. It allows your collaborators to work with your revisions. You will “hand in” your work by Staging any files involved in the work. Committing the staged files. You might want to identify the commit with a message like “Handing in Assignment 2.” Pushing to the server. You’re work will be marked as “handed in” the moment you commit. But the instructor will only be able to see the files you’ve handed in after you push to the cloud server. If you decide to revise your work, simply revise, stage, commit and push again. The instructor will see the new version and will also have access to the earlier versions along with the time stamp made when they were committed. When in doubt about a deadline, push your work. You can always revise and push again if you discover that you have additional time until the deadline. What’s more, you can revise and push again after the deadline. Your instructor will be able to sort out which is the version to use for grading purposes. It is not cheating to revise after the deadline, because the instructor always knows which versions were submitted before the deadline. Indeed, I encourage you to revise your work even after it’s been submitted. That way you will have a copy that reflects your current understanding. By the way, the web site for this course is managed in exactly the same way. The only difference is that whatever clone the server has is made available to web browsers. Vocabulary: You should be able to give an accurate definition of each of these words, and say how they are connected to one another: git, GitHub, clone, stage, commit, push, pull, conflict DT Kaplan, Tue Sep 6 09:20:28 2016 Documents on a computer are always software: instructions to some display system about what image to paint on the computer screen or paper. To paraphrase the artist Magritte, “Ceçi n’est pas un document.” What you write is the software to create a document, just as Magritte’s famous painting of a pipe is a painting, not a pipe.↩ "],
["instructions-for-the-publishing-system-bookdown.html", "Instructions for the publishing system: Bookdown", " Instructions for the publishing system: Bookdown You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter ??. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter ??. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 2.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 2.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 2.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 2.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2016) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). "]
]
